{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from CustomDataModule import CustomDataModule\n",
    "from LSTMModel import LSTMModel\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from pytorch_lightning.utilities.model_summary import summarize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def process_radar_return(radar_return):\n",
    "    # Ensure the radar return has shape (num_rows, num_cols)\n",
    "    assert len(radar_return.shape) == 2\n",
    "\n",
    "    # Define the target length of 512\n",
    "    target_length = 512\n",
    "\n",
    "    # Randomly select the starting index for the sequence\n",
    "    start_index = np.random.randint(0, radar_return.shape[0] - 4)\n",
    "\n",
    "    # Select the subsequent 4 indices to form a sequence of 5 adjacent pulses\n",
    "    selected_pulses = np.arange(start_index, start_index + 5)\n",
    "\n",
    "    # Concatenate selected pulses along rows\n",
    "    concatenated_pulses = np.concatenate([radar_return[pulse, :] for pulse in selected_pulses], axis=0)\n",
    "\n",
    "    # Take np.abs to convert complex numbers to real numbers\n",
    "    epsilon = 1e-10\n",
    "    processed_radar_return = 10 * np.log10(((np.abs(concatenated_pulses))**2)+epsilon)\n",
    "\n",
    "    # Ensure the processed radar return has length 512\n",
    "    if processed_radar_return.shape[0] > target_length:\n",
    "        # If length is greater than 512, truncate the vector\n",
    "        processed_radar_return = processed_radar_return[:target_length]\n",
    "    elif processed_radar_return.shape[0] < target_length:\n",
    "        # If length is less than 512, pad with zeros\n",
    "        min_value = np.min(processed_radar_return)\n",
    "        pad_value = -200\n",
    "        processed_radar_return = np.pad(processed_radar_return,\n",
    "                                        (0, target_length - processed_radar_return.shape[0]),\n",
    "                                        mode='constant', constant_values=pad_value)\n",
    "\n",
    "    return processed_radar_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize_radar_return_column(combined_df):\n",
    "    radar_data = combined_df['radar_return']\n",
    "\n",
    "    # Flatten the radar data for scaler fitting\n",
    "    flattened_data = [np.array(row).flatten() for row in radar_data]\n",
    "    flattened_data = np.concatenate(flattened_data).reshape(-1, 1)\n",
    "\n",
    "    # Fit the scaler on the flattened data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(flattened_data)\n",
    "\n",
    "    # Transform each row separately\n",
    "    normalized_data = [scaler.transform(np.array(row).reshape(-1, 1)).flatten().tolist() for row in radar_data]\n",
    "\n",
    "    # Reshape the normalized data back to its original shape\n",
    "    combined_df['radar_return'] = normalized_data\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'First_data'  # Change this to your data folder path\n",
    "dataframes = []\n",
    "\n",
    "# set device!\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating the dataframe...\n",
      "                                          radar_return  \\\n",
      "0    [-80.75691, -75.623146, -68.651276, -68.17632,...   \n",
      "1    [-62.18104, -75.2347, -74.17063, -76.82196, -7...   \n",
      "2    [-99.71094, -99.85363, -98.71491, -99.19393, -...   \n",
      "3    [-63.654144, -72.61788, -65.20703, -59.84275, ...   \n",
      "4    [-96.05863, -95.810295, -98.290436, -96.82037,...   \n",
      "..                                                 ...   \n",
      "195  [-77.07101, -92.10882, -90.75988, -82.61041, -...   \n",
      "196  [-67.16582, -53.50449, -60.501972, -53.845417,...   \n",
      "197  [-96.33643, -95.2356, -91.85879, -91.16272, -8...   \n",
      "198  [-70.815155, -69.92642, -71.52543, -79.96868, ...   \n",
      "199  [-85.68968, -99.00751, -84.24767, -96.94619, -...   \n",
      "\n",
      "                            object_id  \n",
      "0    1c47c37d6c785d4fe7fd9a18c19837e5  \n",
      "1    1c47c37d6c785d4fe7fd9a18c19837e5  \n",
      "2    1c47c37d6c785d4fe7fd9a18c19837e5  \n",
      "3    1c47c37d6c785d4fe7fd9a18c19837e5  \n",
      "4    1c47c37d6c785d4fe7fd9a18c19837e5  \n",
      "..                                ...  \n",
      "195   cfd06e58d354213c8f2a8ddb5c970b6  \n",
      "196   cfd06e58d354213c8f2a8ddb5c970b6  \n",
      "197   cfd06e58d354213c8f2a8ddb5c970b6  \n",
      "198   cfd06e58d354213c8f2a8ddb5c970b6  \n",
      "199   cfd06e58d354213c8f2a8ddb5c970b6  \n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"creating the dataframe...\")\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.pickle'):\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            # Load data from pickle file\n",
    "            data = pickle.load(f)\n",
    "            # Extract radar_return and object_id\n",
    "            radar_return = data['radar_return']\n",
    "            object_id = data['object_id']\n",
    "            # Concatenate radar_return along the columns\n",
    "            concatenated_radar = process_radar_return(radar_return).astype('float32')\n",
    "            # Create a DataFrame with concatenated radar and object_id\n",
    "            df = pd.DataFrame({'radar_return': [concatenated_radar], 'object_id': [object_id]})\n",
    "            # Append the DataFrame to the list\n",
    "            dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "combined_df = pd.concat(dataframes[::100], ignore_index=True)\n",
    "#combined_df = normalize_radar_return_column(combined_df)\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class RadarDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "radar_data = torch.tensor(combined_df['radar_return'].values.tolist(), dtype=torch.float32)\n",
    "object_ids = combined_df['object_id'].values.tolist()\n",
    "# Use LabelEncoder to convert object_ids to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "object_ids_encoded = label_encoder.fit_transform(object_ids)\n",
    "print(object_ids_encoded)\n",
    "\n",
    "# Convert encoded labels to tensor\n",
    "object_ids_tensor = torch.tensor(object_ids_encoded, dtype=torch.float32)\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = radar_data.shape[1]\n",
    "hidden_size = 512\n",
    "output_size = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "# Create FNN instance\n",
    "model = FNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create DataLoader for batch training\n",
    "dataset = RadarDataset(radar_data, object_ids_tensor)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FNN(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Step [1/7], Loss: 0.0235, Accuracy: 0.0938\n",
      "Epoch [1/200], Step [2/7], Loss: 0.0246, Accuracy: 0.1250\n",
      "Epoch [1/200], Step [3/7], Loss: 0.0231, Accuracy: 0.1250\n",
      "Epoch [1/200], Step [4/7], Loss: 0.0278, Accuracy: 0.0312\n",
      "Epoch [1/200], Step [5/7], Loss: 0.0241, Accuracy: 0.0312\n",
      "Epoch [1/200], Step [6/7], Loss: 0.0265, Accuracy: 0.0625\n",
      "Epoch [1/200], Step [7/7], Loss: 0.0249, Accuracy: 0.0000\n",
      "Epoch [2/200], Step [1/7], Loss: 0.0192, Accuracy: 0.4062\n",
      "Epoch [2/200], Step [2/7], Loss: 0.0210, Accuracy: 0.2812\n",
      "Epoch [2/200], Step [3/7], Loss: 0.0192, Accuracy: 0.3438\n",
      "Epoch [2/200], Step [4/7], Loss: 0.0184, Accuracy: 0.3750\n",
      "Epoch [2/200], Step [5/7], Loss: 0.0208, Accuracy: 0.3125\n",
      "Epoch [2/200], Step [6/7], Loss: 0.0198, Accuracy: 0.3125\n",
      "Epoch [2/200], Step [7/7], Loss: 0.0201, Accuracy: 0.3750\n",
      "Epoch [3/200], Step [1/7], Loss: 0.0179, Accuracy: 0.4375\n",
      "Epoch [3/200], Step [2/7], Loss: 0.0179, Accuracy: 0.4688\n",
      "Epoch [3/200], Step [3/7], Loss: 0.0179, Accuracy: 0.3750\n",
      "Epoch [3/200], Step [4/7], Loss: 0.0185, Accuracy: 0.3750\n",
      "Epoch [3/200], Step [5/7], Loss: 0.0176, Accuracy: 0.3125\n",
      "Epoch [3/200], Step [6/7], Loss: 0.0192, Accuracy: 0.3438\n",
      "Epoch [3/200], Step [7/7], Loss: 0.0213, Accuracy: 0.2500\n",
      "Epoch [4/200], Step [1/7], Loss: 0.0169, Accuracy: 0.3750\n",
      "Epoch [4/200], Step [2/7], Loss: 0.0171, Accuracy: 0.5938\n",
      "Epoch [4/200], Step [3/7], Loss: 0.0158, Accuracy: 0.5625\n",
      "Epoch [4/200], Step [4/7], Loss: 0.0157, Accuracy: 0.6562\n",
      "Epoch [4/200], Step [5/7], Loss: 0.0158, Accuracy: 0.5625\n",
      "Epoch [4/200], Step [6/7], Loss: 0.0154, Accuracy: 0.5938\n",
      "Epoch [4/200], Step [7/7], Loss: 0.0185, Accuracy: 0.1250\n",
      "Epoch [5/200], Step [1/7], Loss: 0.0136, Accuracy: 0.6875\n",
      "Epoch [5/200], Step [2/7], Loss: 0.0138, Accuracy: 0.5000\n",
      "Epoch [5/200], Step [3/7], Loss: 0.0144, Accuracy: 0.5312\n",
      "Epoch [5/200], Step [4/7], Loss: 0.0148, Accuracy: 0.6250\n",
      "Epoch [5/200], Step [5/7], Loss: 0.0142, Accuracy: 0.6562\n",
      "Epoch [5/200], Step [6/7], Loss: 0.0140, Accuracy: 0.5938\n",
      "Epoch [5/200], Step [7/7], Loss: 0.0139, Accuracy: 0.8750\n",
      "Epoch [6/200], Step [1/7], Loss: 0.0115, Accuracy: 0.8125\n",
      "Epoch [6/200], Step [2/7], Loss: 0.0105, Accuracy: 0.8438\n",
      "Epoch [6/200], Step [3/7], Loss: 0.0129, Accuracy: 0.5312\n",
      "Epoch [6/200], Step [4/7], Loss: 0.0127, Accuracy: 0.6250\n",
      "Epoch [6/200], Step [5/7], Loss: 0.0138, Accuracy: 0.5312\n",
      "Epoch [6/200], Step [6/7], Loss: 0.0126, Accuracy: 0.7188\n",
      "Epoch [6/200], Step [7/7], Loss: 0.0137, Accuracy: 0.6250\n",
      "Epoch [7/200], Step [1/7], Loss: 0.0095, Accuracy: 0.8750\n",
      "Epoch [7/200], Step [2/7], Loss: 0.0083, Accuracy: 0.9375\n",
      "Epoch [7/200], Step [3/7], Loss: 0.0104, Accuracy: 0.8125\n",
      "Epoch [7/200], Step [4/7], Loss: 0.0124, Accuracy: 0.5625\n",
      "Epoch [7/200], Step [5/7], Loss: 0.0115, Accuracy: 0.6562\n",
      "Epoch [7/200], Step [6/7], Loss: 0.0118, Accuracy: 0.6562\n",
      "Epoch [7/200], Step [7/7], Loss: 0.0108, Accuracy: 0.8750\n",
      "Epoch [8/200], Step [1/7], Loss: 0.0096, Accuracy: 0.7812\n",
      "Epoch [8/200], Step [2/7], Loss: 0.0084, Accuracy: 0.8438\n",
      "Epoch [8/200], Step [3/7], Loss: 0.0084, Accuracy: 0.8125\n",
      "Epoch [8/200], Step [4/7], Loss: 0.0103, Accuracy: 0.8125\n",
      "Epoch [8/200], Step [5/7], Loss: 0.0082, Accuracy: 0.9062\n",
      "Epoch [8/200], Step [6/7], Loss: 0.0098, Accuracy: 0.8125\n",
      "Epoch [8/200], Step [7/7], Loss: 0.0104, Accuracy: 0.7500\n",
      "Epoch [9/200], Step [1/7], Loss: 0.0076, Accuracy: 0.8438\n",
      "Epoch [9/200], Step [2/7], Loss: 0.0077, Accuracy: 0.8750\n",
      "Epoch [9/200], Step [3/7], Loss: 0.0070, Accuracy: 0.8438\n",
      "Epoch [9/200], Step [4/7], Loss: 0.0068, Accuracy: 0.9062\n",
      "Epoch [9/200], Step [5/7], Loss: 0.0079, Accuracy: 0.7500\n",
      "Epoch [9/200], Step [6/7], Loss: 0.0077, Accuracy: 0.9062\n",
      "Epoch [9/200], Step [7/7], Loss: 0.0108, Accuracy: 0.7500\n",
      "Epoch [10/200], Step [1/7], Loss: 0.0051, Accuracy: 0.9375\n",
      "Epoch [10/200], Step [2/7], Loss: 0.0058, Accuracy: 0.9062\n",
      "Epoch [10/200], Step [3/7], Loss: 0.0048, Accuracy: 0.9688\n",
      "Epoch [10/200], Step [4/7], Loss: 0.0085, Accuracy: 0.8125\n",
      "Epoch [10/200], Step [5/7], Loss: 0.0080, Accuracy: 0.7500\n",
      "Epoch [10/200], Step [6/7], Loss: 0.0073, Accuracy: 0.8438\n",
      "Epoch [10/200], Step [7/7], Loss: 0.0088, Accuracy: 0.6250\n",
      "Epoch [11/200], Step [1/7], Loss: 0.0052, Accuracy: 0.9688\n",
      "Epoch [11/200], Step [2/7], Loss: 0.0066, Accuracy: 0.8438\n",
      "Epoch [11/200], Step [3/7], Loss: 0.0068, Accuracy: 0.8438\n",
      "Epoch [11/200], Step [4/7], Loss: 0.0042, Accuracy: 0.9062\n",
      "Epoch [11/200], Step [5/7], Loss: 0.0076, Accuracy: 0.8125\n",
      "Epoch [11/200], Step [6/7], Loss: 0.0066, Accuracy: 0.9062\n",
      "Epoch [11/200], Step [7/7], Loss: 0.0167, Accuracy: 0.3750\n",
      "Epoch [12/200], Step [1/7], Loss: 0.0053, Accuracy: 0.9062\n",
      "Epoch [12/200], Step [2/7], Loss: 0.0053, Accuracy: 0.8750\n",
      "Epoch [12/200], Step [3/7], Loss: 0.0067, Accuracy: 0.9375\n",
      "Epoch [12/200], Step [4/7], Loss: 0.0051, Accuracy: 0.9375\n",
      "Epoch [12/200], Step [5/7], Loss: 0.0066, Accuracy: 0.9062\n",
      "Epoch [12/200], Step [6/7], Loss: 0.0058, Accuracy: 0.8750\n",
      "Epoch [12/200], Step [7/7], Loss: 0.0096, Accuracy: 0.7500\n",
      "Epoch [13/200], Step [1/7], Loss: 0.0046, Accuracy: 0.9375\n",
      "Epoch [13/200], Step [2/7], Loss: 0.0064, Accuracy: 0.9062\n",
      "Epoch [13/200], Step [3/7], Loss: 0.0061, Accuracy: 0.8438\n",
      "Epoch [13/200], Step [4/7], Loss: 0.0045, Accuracy: 0.9375\n",
      "Epoch [13/200], Step [5/7], Loss: 0.0067, Accuracy: 0.8750\n",
      "Epoch [13/200], Step [6/7], Loss: 0.0070, Accuracy: 0.8438\n",
      "Epoch [13/200], Step [7/7], Loss: 0.0038, Accuracy: 1.0000\n",
      "Epoch [14/200], Step [1/7], Loss: 0.0050, Accuracy: 0.9062\n",
      "Epoch [14/200], Step [2/7], Loss: 0.0049, Accuracy: 0.9375\n",
      "Epoch [14/200], Step [3/7], Loss: 0.0038, Accuracy: 0.9688\n",
      "Epoch [14/200], Step [4/7], Loss: 0.0053, Accuracy: 0.8750\n",
      "Epoch [14/200], Step [5/7], Loss: 0.0040, Accuracy: 0.9375\n",
      "Epoch [14/200], Step [6/7], Loss: 0.0057, Accuracy: 0.8750\n",
      "Epoch [14/200], Step [7/7], Loss: 0.0090, Accuracy: 0.7500\n",
      "Epoch [15/200], Step [1/7], Loss: 0.0046, Accuracy: 0.9375\n",
      "Epoch [15/200], Step [2/7], Loss: 0.0037, Accuracy: 0.9688\n",
      "Epoch [15/200], Step [3/7], Loss: 0.0044, Accuracy: 0.9375\n",
      "Epoch [15/200], Step [4/7], Loss: 0.0038, Accuracy: 0.9375\n",
      "Epoch [15/200], Step [5/7], Loss: 0.0046, Accuracy: 0.9062\n",
      "Epoch [15/200], Step [6/7], Loss: 0.0038, Accuracy: 1.0000\n",
      "Epoch [15/200], Step [7/7], Loss: 0.0038, Accuracy: 1.0000\n",
      "Epoch [16/200], Step [1/7], Loss: 0.0030, Accuracy: 0.9688\n",
      "Epoch [16/200], Step [2/7], Loss: 0.0045, Accuracy: 0.9375\n",
      "Epoch [16/200], Step [3/7], Loss: 0.0042, Accuracy: 0.9375\n",
      "Epoch [16/200], Step [4/7], Loss: 0.0037, Accuracy: 0.9688\n",
      "Epoch [16/200], Step [5/7], Loss: 0.0044, Accuracy: 0.9062\n",
      "Epoch [16/200], Step [6/7], Loss: 0.0034, Accuracy: 1.0000\n",
      "Epoch [16/200], Step [7/7], Loss: 0.0107, Accuracy: 0.6250\n",
      "Epoch [17/200], Step [1/7], Loss: 0.0030, Accuracy: 0.9688\n",
      "Epoch [17/200], Step [2/7], Loss: 0.0032, Accuracy: 0.9688\n",
      "Epoch [17/200], Step [3/7], Loss: 0.0036, Accuracy: 0.9375\n",
      "Epoch [17/200], Step [4/7], Loss: 0.0022, Accuracy: 1.0000\n",
      "Epoch [17/200], Step [5/7], Loss: 0.0026, Accuracy: 0.9688\n",
      "Epoch [17/200], Step [6/7], Loss: 0.0028, Accuracy: 1.0000\n",
      "Epoch [17/200], Step [7/7], Loss: 0.0099, Accuracy: 0.6250\n",
      "Epoch [18/200], Step [1/7], Loss: 0.0022, Accuracy: 0.9688\n",
      "Epoch [18/200], Step [2/7], Loss: 0.0041, Accuracy: 0.9688\n",
      "Epoch [18/200], Step [3/7], Loss: 0.0027, Accuracy: 0.9375\n",
      "Epoch [18/200], Step [4/7], Loss: 0.0034, Accuracy: 0.9375\n",
      "Epoch [18/200], Step [5/7], Loss: 0.0058, Accuracy: 0.8125\n",
      "Epoch [18/200], Step [6/7], Loss: 0.0041, Accuracy: 0.8750\n",
      "Epoch [18/200], Step [7/7], Loss: 0.0102, Accuracy: 0.6250\n",
      "Epoch [19/200], Step [1/7], Loss: 0.0028, Accuracy: 0.9688\n",
      "Epoch [19/200], Step [2/7], Loss: 0.0022, Accuracy: 1.0000\n",
      "Epoch [19/200], Step [3/7], Loss: 0.0046, Accuracy: 0.8438\n",
      "Epoch [19/200], Step [4/7], Loss: 0.0033, Accuracy: 0.9375\n",
      "Epoch [19/200], Step [5/7], Loss: 0.0039, Accuracy: 0.9062\n",
      "Epoch [19/200], Step [6/7], Loss: 0.0040, Accuracy: 0.9375\n",
      "Epoch [19/200], Step [7/7], Loss: 0.0100, Accuracy: 0.7500\n",
      "Epoch [20/200], Step [1/7], Loss: 0.0027, Accuracy: 0.9688\n",
      "Epoch [20/200], Step [2/7], Loss: 0.0022, Accuracy: 1.0000\n",
      "Epoch [20/200], Step [3/7], Loss: 0.0036, Accuracy: 0.9375\n",
      "Epoch [20/200], Step [4/7], Loss: 0.0053, Accuracy: 0.8438\n",
      "Epoch [20/200], Step [5/7], Loss: 0.0028, Accuracy: 0.9688\n",
      "Epoch [20/200], Step [6/7], Loss: 0.0043, Accuracy: 0.9062\n",
      "Epoch [20/200], Step [7/7], Loss: 0.0059, Accuracy: 0.8750\n",
      "Epoch [21/200], Step [1/7], Loss: 0.0026, Accuracy: 1.0000\n",
      "Epoch [21/200], Step [2/7], Loss: 0.0031, Accuracy: 0.9062\n",
      "Epoch [21/200], Step [3/7], Loss: 0.0026, Accuracy: 0.9688\n",
      "Epoch [21/200], Step [4/7], Loss: 0.0032, Accuracy: 0.9375\n",
      "Epoch [21/200], Step [5/7], Loss: 0.0031, Accuracy: 0.9688\n",
      "Epoch [21/200], Step [6/7], Loss: 0.0046, Accuracy: 0.9062\n",
      "Epoch [21/200], Step [7/7], Loss: 0.0026, Accuracy: 1.0000\n",
      "Epoch [22/200], Step [1/7], Loss: 0.0030, Accuracy: 0.9688\n",
      "Epoch [22/200], Step [2/7], Loss: 0.0024, Accuracy: 1.0000\n",
      "Epoch [22/200], Step [3/7], Loss: 0.0022, Accuracy: 1.0000\n",
      "Epoch [22/200], Step [4/7], Loss: 0.0029, Accuracy: 0.9688\n",
      "Epoch [22/200], Step [5/7], Loss: 0.0040, Accuracy: 0.9375\n",
      "Epoch [22/200], Step [6/7], Loss: 0.0021, Accuracy: 1.0000\n",
      "Epoch [22/200], Step [7/7], Loss: 0.0059, Accuracy: 0.7500\n",
      "Epoch [23/200], Step [1/7], Loss: 0.0022, Accuracy: 1.0000\n",
      "Epoch [23/200], Step [2/7], Loss: 0.0018, Accuracy: 0.9688\n",
      "Epoch [23/200], Step [3/7], Loss: 0.0036, Accuracy: 0.9688\n",
      "Epoch [23/200], Step [4/7], Loss: 0.0051, Accuracy: 0.8750\n",
      "Epoch [23/200], Step [5/7], Loss: 0.0025, Accuracy: 0.9688\n",
      "Epoch [23/200], Step [6/7], Loss: 0.0016, Accuracy: 1.0000\n",
      "Epoch [23/200], Step [7/7], Loss: 0.0070, Accuracy: 0.6250\n",
      "Epoch [24/200], Step [1/7], Loss: 0.0017, Accuracy: 0.9688\n",
      "Epoch [24/200], Step [2/7], Loss: 0.0024, Accuracy: 1.0000\n",
      "Epoch [24/200], Step [3/7], Loss: 0.0028, Accuracy: 0.9375\n",
      "Epoch [24/200], Step [4/7], Loss: 0.0048, Accuracy: 0.8438\n",
      "Epoch [24/200], Step [5/7], Loss: 0.0028, Accuracy: 0.9375\n",
      "Epoch [24/200], Step [6/7], Loss: 0.0025, Accuracy: 0.9688\n",
      "Epoch [24/200], Step [7/7], Loss: 0.0122, Accuracy: 0.6250\n",
      "Epoch [25/200], Step [1/7], Loss: 0.0019, Accuracy: 1.0000\n",
      "Epoch [25/200], Step [2/7], Loss: 0.0031, Accuracy: 0.9375\n",
      "Epoch [25/200], Step [3/7], Loss: 0.0022, Accuracy: 0.9688\n",
      "Epoch [25/200], Step [4/7], Loss: 0.0023, Accuracy: 0.9688\n",
      "Epoch [25/200], Step [5/7], Loss: 0.0022, Accuracy: 0.9688\n",
      "Epoch [25/200], Step [6/7], Loss: 0.0026, Accuracy: 0.9688\n",
      "Epoch [25/200], Step [7/7], Loss: 0.0046, Accuracy: 0.8750\n",
      "Epoch [26/200], Step [1/7], Loss: 0.0014, Accuracy: 1.0000\n",
      "Epoch [26/200], Step [2/7], Loss: 0.0019, Accuracy: 1.0000\n",
      "Epoch [26/200], Step [3/7], Loss: 0.0029, Accuracy: 0.9688\n",
      "Epoch [26/200], Step [4/7], Loss: 0.0021, Accuracy: 0.9688\n",
      "Epoch [26/200], Step [5/7], Loss: 0.0022, Accuracy: 1.0000\n",
      "Epoch [26/200], Step [6/7], Loss: 0.0026, Accuracy: 0.9375\n",
      "Epoch [26/200], Step [7/7], Loss: 0.0034, Accuracy: 1.0000\n",
      "Epoch [27/200], Step [1/7], Loss: 0.0016, Accuracy: 1.0000\n",
      "Epoch [27/200], Step [2/7], Loss: 0.0024, Accuracy: 0.9688\n",
      "Epoch [27/200], Step [3/7], Loss: 0.0026, Accuracy: 0.9688\n",
      "Epoch [27/200], Step [4/7], Loss: 0.0027, Accuracy: 0.9375\n",
      "Epoch [27/200], Step [5/7], Loss: 0.0024, Accuracy: 0.9688\n",
      "Epoch [27/200], Step [6/7], Loss: 0.0015, Accuracy: 1.0000\n",
      "Epoch [27/200], Step [7/7], Loss: 0.0075, Accuracy: 0.7500\n",
      "Epoch [28/200], Step [1/7], Loss: 0.0021, Accuracy: 0.9688\n",
      "Epoch [28/200], Step [2/7], Loss: 0.0019, Accuracy: 0.9688\n",
      "Epoch [28/200], Step [3/7], Loss: 0.0053, Accuracy: 0.8125\n",
      "Epoch [28/200], Step [4/7], Loss: 0.0027, Accuracy: 0.9688\n",
      "Epoch [28/200], Step [5/7], Loss: 0.0018, Accuracy: 0.9688\n",
      "Epoch [28/200], Step [6/7], Loss: 0.0025, Accuracy: 0.9688\n",
      "Epoch [28/200], Step [7/7], Loss: 0.0071, Accuracy: 0.8750\n",
      "Epoch [29/200], Step [1/7], Loss: 0.0016, Accuracy: 1.0000\n",
      "Epoch [29/200], Step [2/7], Loss: 0.0027, Accuracy: 0.9375\n",
      "Epoch [29/200], Step [3/7], Loss: 0.0022, Accuracy: 0.9375\n",
      "Epoch [29/200], Step [4/7], Loss: 0.0027, Accuracy: 0.9375\n",
      "Epoch [29/200], Step [5/7], Loss: 0.0035, Accuracy: 0.9375\n",
      "Epoch [29/200], Step [6/7], Loss: 0.0050, Accuracy: 0.9375\n",
      "Epoch [29/200], Step [7/7], Loss: 0.0110, Accuracy: 0.6250\n",
      "Epoch [30/200], Step [1/7], Loss: 0.0018, Accuracy: 1.0000\n",
      "Epoch [30/200], Step [2/7], Loss: 0.0020, Accuracy: 0.9688\n",
      "Epoch [30/200], Step [3/7], Loss: 0.0024, Accuracy: 1.0000\n",
      "Epoch [30/200], Step [4/7], Loss: 0.0025, Accuracy: 0.9375\n",
      "Epoch [30/200], Step [5/7], Loss: 0.0029, Accuracy: 0.9688\n",
      "Epoch [30/200], Step [6/7], Loss: 0.0045, Accuracy: 0.8750\n",
      "Epoch [30/200], Step [7/7], Loss: 0.0158, Accuracy: 0.3750\n",
      "Epoch [31/200], Step [1/7], Loss: 0.0025, Accuracy: 1.0000\n",
      "Epoch [31/200], Step [2/7], Loss: 0.0026, Accuracy: 0.9375\n",
      "Epoch [31/200], Step [3/7], Loss: 0.0020, Accuracy: 0.9375\n",
      "Epoch [31/200], Step [4/7], Loss: 0.0040, Accuracy: 0.8750\n",
      "Epoch [31/200], Step [5/7], Loss: 0.0028, Accuracy: 0.9688\n",
      "Epoch [31/200], Step [6/7], Loss: 0.0048, Accuracy: 0.8750\n",
      "Epoch [31/200], Step [7/7], Loss: 0.0056, Accuracy: 0.7500\n",
      "Epoch [32/200], Step [1/7], Loss: 0.0021, Accuracy: 1.0000\n",
      "Epoch [32/200], Step [2/7], Loss: 0.0019, Accuracy: 1.0000\n",
      "Epoch [32/200], Step [3/7], Loss: 0.0033, Accuracy: 0.9062\n",
      "Epoch [32/200], Step [4/7], Loss: 0.0039, Accuracy: 0.9062\n",
      "Epoch [32/200], Step [5/7], Loss: 0.0035, Accuracy: 0.9062\n",
      "Epoch [32/200], Step [6/7], Loss: 0.0034, Accuracy: 0.9062\n",
      "Epoch [32/200], Step [7/7], Loss: 0.0092, Accuracy: 0.8750\n",
      "Epoch [33/200], Step [1/7], Loss: 0.0015, Accuracy: 0.9688\n",
      "Epoch [33/200], Step [2/7], Loss: 0.0027, Accuracy: 1.0000\n",
      "Epoch [33/200], Step [3/7], Loss: 0.0035, Accuracy: 0.9375\n",
      "Epoch [33/200], Step [4/7], Loss: 0.0029, Accuracy: 0.9375\n",
      "Epoch [33/200], Step [5/7], Loss: 0.0015, Accuracy: 1.0000\n",
      "Epoch [33/200], Step [6/7], Loss: 0.0019, Accuracy: 1.0000\n",
      "Epoch [33/200], Step [7/7], Loss: 0.0044, Accuracy: 0.8750\n",
      "Epoch [34/200], Step [1/7], Loss: 0.0017, Accuracy: 1.0000\n",
      "Epoch [34/200], Step [2/7], Loss: 0.0018, Accuracy: 1.0000\n",
      "Epoch [34/200], Step [3/7], Loss: 0.0021, Accuracy: 0.9688\n",
      "Epoch [34/200], Step [4/7], Loss: 0.0014, Accuracy: 0.9688\n",
      "Epoch [34/200], Step [5/7], Loss: 0.0013, Accuracy: 1.0000\n",
      "Epoch [34/200], Step [6/7], Loss: 0.0027, Accuracy: 0.9688\n",
      "Epoch [34/200], Step [7/7], Loss: 0.0047, Accuracy: 0.8750\n",
      "Epoch [35/200], Step [1/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [35/200], Step [2/7], Loss: 0.0031, Accuracy: 0.9375\n",
      "Epoch [35/200], Step [3/7], Loss: 0.0018, Accuracy: 0.9375\n",
      "Epoch [35/200], Step [4/7], Loss: 0.0021, Accuracy: 0.9375\n",
      "Epoch [35/200], Step [5/7], Loss: 0.0065, Accuracy: 0.8438\n",
      "Epoch [35/200], Step [6/7], Loss: 0.0033, Accuracy: 0.9375\n",
      "Epoch [35/200], Step [7/7], Loss: 0.0079, Accuracy: 0.7500\n",
      "Epoch [36/200], Step [1/7], Loss: 0.0023, Accuracy: 0.9688\n",
      "Epoch [36/200], Step [2/7], Loss: 0.0033, Accuracy: 0.9688\n",
      "Epoch [36/200], Step [3/7], Loss: 0.0020, Accuracy: 0.9375\n",
      "Epoch [36/200], Step [4/7], Loss: 0.0022, Accuracy: 0.9688\n",
      "Epoch [36/200], Step [5/7], Loss: 0.0035, Accuracy: 0.9375\n",
      "Epoch [36/200], Step [6/7], Loss: 0.0056, Accuracy: 0.9062\n",
      "Epoch [36/200], Step [7/7], Loss: 0.0090, Accuracy: 0.6250\n",
      "Epoch [37/200], Step [1/7], Loss: 0.0016, Accuracy: 0.9688\n",
      "Epoch [37/200], Step [2/7], Loss: 0.0012, Accuracy: 1.0000\n",
      "Epoch [37/200], Step [3/7], Loss: 0.0018, Accuracy: 0.9688\n",
      "Epoch [37/200], Step [4/7], Loss: 0.0046, Accuracy: 0.7812\n",
      "Epoch [37/200], Step [5/7], Loss: 0.0036, Accuracy: 0.9062\n",
      "Epoch [37/200], Step [6/7], Loss: 0.0045, Accuracy: 0.9062\n",
      "Epoch [37/200], Step [7/7], Loss: 0.0052, Accuracy: 0.8750\n",
      "Epoch [38/200], Step [1/7], Loss: 0.0022, Accuracy: 0.9688\n",
      "Epoch [38/200], Step [2/7], Loss: 0.0021, Accuracy: 0.9375\n",
      "Epoch [38/200], Step [3/7], Loss: 0.0026, Accuracy: 1.0000\n",
      "Epoch [38/200], Step [4/7], Loss: 0.0021, Accuracy: 0.9688\n",
      "Epoch [38/200], Step [5/7], Loss: 0.0027, Accuracy: 0.9688\n",
      "Epoch [38/200], Step [6/7], Loss: 0.0023, Accuracy: 0.9688\n",
      "Epoch [38/200], Step [7/7], Loss: 0.0047, Accuracy: 0.8750\n",
      "Epoch [39/200], Step [1/7], Loss: 0.0015, Accuracy: 0.9688\n",
      "Epoch [39/200], Step [2/7], Loss: 0.0015, Accuracy: 1.0000\n",
      "Epoch [39/200], Step [3/7], Loss: 0.0031, Accuracy: 0.8750\n",
      "Epoch [39/200], Step [4/7], Loss: 0.0033, Accuracy: 0.8750\n",
      "Epoch [39/200], Step [5/7], Loss: 0.0012, Accuracy: 1.0000\n",
      "Epoch [39/200], Step [6/7], Loss: 0.0041, Accuracy: 0.8438\n",
      "Epoch [39/200], Step [7/7], Loss: 0.0030, Accuracy: 0.8750\n",
      "Epoch [40/200], Step [1/7], Loss: 0.0017, Accuracy: 0.9688\n",
      "Epoch [40/200], Step [2/7], Loss: 0.0020, Accuracy: 1.0000\n",
      "Epoch [40/200], Step [3/7], Loss: 0.0018, Accuracy: 0.9688\n",
      "Epoch [40/200], Step [4/7], Loss: 0.0020, Accuracy: 0.9688\n",
      "Epoch [40/200], Step [5/7], Loss: 0.0015, Accuracy: 0.9375\n",
      "Epoch [40/200], Step [6/7], Loss: 0.0017, Accuracy: 0.9375\n",
      "Epoch [40/200], Step [7/7], Loss: 0.0015, Accuracy: 1.0000\n",
      "Epoch [41/200], Step [1/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [41/200], Step [2/7], Loss: 0.0019, Accuracy: 0.9375\n",
      "Epoch [41/200], Step [3/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [41/200], Step [4/7], Loss: 0.0011, Accuracy: 0.9688\n",
      "Epoch [41/200], Step [5/7], Loss: 0.0021, Accuracy: 0.9688\n",
      "Epoch [41/200], Step [6/7], Loss: 0.0010, Accuracy: 0.9688\n",
      "Epoch [41/200], Step [7/7], Loss: 0.0063, Accuracy: 0.7500\n",
      "Epoch [42/200], Step [1/7], Loss: 0.0018, Accuracy: 0.9688\n",
      "Epoch [42/200], Step [2/7], Loss: 0.0012, Accuracy: 1.0000\n",
      "Epoch [42/200], Step [3/7], Loss: 0.0018, Accuracy: 0.9688\n",
      "Epoch [42/200], Step [4/7], Loss: 0.0028, Accuracy: 0.9375\n",
      "Epoch [42/200], Step [5/7], Loss: 0.0020, Accuracy: 0.9375\n",
      "Epoch [42/200], Step [6/7], Loss: 0.0034, Accuracy: 0.9062\n",
      "Epoch [42/200], Step [7/7], Loss: 0.0019, Accuracy: 1.0000\n",
      "Epoch [43/200], Step [1/7], Loss: 0.0014, Accuracy: 0.9688\n",
      "Epoch [43/200], Step [2/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [43/200], Step [3/7], Loss: 0.0027, Accuracy: 0.9062\n",
      "Epoch [43/200], Step [4/7], Loss: 0.0013, Accuracy: 0.9688\n",
      "Epoch [43/200], Step [5/7], Loss: 0.0013, Accuracy: 0.9688\n",
      "Epoch [43/200], Step [6/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [43/200], Step [7/7], Loss: 0.0023, Accuracy: 1.0000\n",
      "Epoch [44/200], Step [1/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [44/200], Step [2/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [44/200], Step [3/7], Loss: 0.0016, Accuracy: 0.9688\n",
      "Epoch [44/200], Step [4/7], Loss: 0.0014, Accuracy: 1.0000\n",
      "Epoch [44/200], Step [5/7], Loss: 0.0028, Accuracy: 0.9062\n",
      "Epoch [44/200], Step [6/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [44/200], Step [7/7], Loss: 0.0020, Accuracy: 1.0000\n",
      "Epoch [45/200], Step [1/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [45/200], Step [2/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [45/200], Step [3/7], Loss: 0.0014, Accuracy: 1.0000\n",
      "Epoch [45/200], Step [4/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [45/200], Step [5/7], Loss: 0.0019, Accuracy: 0.9062\n",
      "Epoch [45/200], Step [6/7], Loss: 0.0014, Accuracy: 0.9688\n",
      "Epoch [45/200], Step [7/7], Loss: 0.0023, Accuracy: 1.0000\n",
      "Epoch [46/200], Step [1/7], Loss: 0.0016, Accuracy: 0.9688\n",
      "Epoch [46/200], Step [2/7], Loss: 0.0018, Accuracy: 0.9375\n",
      "Epoch [46/200], Step [3/7], Loss: 0.0015, Accuracy: 0.9375\n",
      "Epoch [46/200], Step [4/7], Loss: 0.0012, Accuracy: 0.9688\n",
      "Epoch [46/200], Step [5/7], Loss: 0.0011, Accuracy: 0.9688\n",
      "Epoch [46/200], Step [6/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [46/200], Step [7/7], Loss: 0.0072, Accuracy: 0.7500\n",
      "Epoch [47/200], Step [1/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [47/200], Step [2/7], Loss: 0.0013, Accuracy: 1.0000\n",
      "Epoch [47/200], Step [3/7], Loss: 0.0011, Accuracy: 0.9688\n",
      "Epoch [47/200], Step [4/7], Loss: 0.0050, Accuracy: 0.9062\n",
      "Epoch [47/200], Step [5/7], Loss: 0.0027, Accuracy: 0.9062\n",
      "Epoch [47/200], Step [6/7], Loss: 0.0028, Accuracy: 0.9375\n",
      "Epoch [47/200], Step [7/7], Loss: 0.0024, Accuracy: 1.0000\n",
      "Epoch [48/200], Step [1/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [48/200], Step [2/7], Loss: 0.0018, Accuracy: 0.9688\n",
      "Epoch [48/200], Step [3/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [48/200], Step [4/7], Loss: 0.0021, Accuracy: 0.9688\n",
      "Epoch [48/200], Step [5/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [48/200], Step [6/7], Loss: 0.0017, Accuracy: 0.9688\n",
      "Epoch [48/200], Step [7/7], Loss: 0.0055, Accuracy: 0.7500\n",
      "Epoch [49/200], Step [1/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [49/200], Step [2/7], Loss: 0.0013, Accuracy: 0.9688\n",
      "Epoch [49/200], Step [3/7], Loss: 0.0011, Accuracy: 1.0000\n",
      "Epoch [49/200], Step [4/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [49/200], Step [5/7], Loss: 0.0014, Accuracy: 0.9375\n",
      "Epoch [49/200], Step [6/7], Loss: 0.0022, Accuracy: 0.9375\n",
      "Epoch [49/200], Step [7/7], Loss: 0.0063, Accuracy: 0.6250\n",
      "Epoch [50/200], Step [1/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [50/200], Step [2/7], Loss: 0.0029, Accuracy: 0.8750\n",
      "Epoch [50/200], Step [3/7], Loss: 0.0013, Accuracy: 0.9375\n",
      "Epoch [50/200], Step [4/7], Loss: 0.0022, Accuracy: 0.9375\n",
      "Epoch [50/200], Step [5/7], Loss: 0.0025, Accuracy: 0.9062\n",
      "Epoch [50/200], Step [6/7], Loss: 0.0012, Accuracy: 1.0000\n",
      "Epoch [50/200], Step [7/7], Loss: 0.0047, Accuracy: 0.8750\n",
      "Epoch [51/200], Step [1/7], Loss: 0.0014, Accuracy: 0.9688\n",
      "Epoch [51/200], Step [2/7], Loss: 0.0014, Accuracy: 1.0000\n",
      "Epoch [51/200], Step [3/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [51/200], Step [4/7], Loss: 0.0015, Accuracy: 0.9688\n",
      "Epoch [51/200], Step [5/7], Loss: 0.0018, Accuracy: 0.9375\n",
      "Epoch [51/200], Step [6/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [51/200], Step [7/7], Loss: 0.0022, Accuracy: 0.8750\n",
      "Epoch [52/200], Step [1/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [52/200], Step [2/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [52/200], Step [3/7], Loss: 0.0020, Accuracy: 0.9688\n",
      "Epoch [52/200], Step [4/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [52/200], Step [5/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [52/200], Step [6/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [52/200], Step [7/7], Loss: 0.0033, Accuracy: 0.8750\n",
      "Epoch [53/200], Step [1/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [53/200], Step [2/7], Loss: 0.0021, Accuracy: 0.9375\n",
      "Epoch [53/200], Step [3/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [53/200], Step [4/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [53/200], Step [5/7], Loss: 0.0020, Accuracy: 0.9688\n",
      "Epoch [53/200], Step [6/7], Loss: 0.0011, Accuracy: 0.9688\n",
      "Epoch [53/200], Step [7/7], Loss: 0.0049, Accuracy: 0.7500\n",
      "Epoch [54/200], Step [1/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [54/200], Step [2/7], Loss: 0.0019, Accuracy: 0.9688\n",
      "Epoch [54/200], Step [3/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [54/200], Step [4/7], Loss: 0.0023, Accuracy: 0.9062\n",
      "Epoch [54/200], Step [5/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [54/200], Step [6/7], Loss: 0.0012, Accuracy: 0.9688\n",
      "Epoch [54/200], Step [7/7], Loss: 0.0012, Accuracy: 1.0000\n",
      "Epoch [55/200], Step [1/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [55/200], Step [2/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [55/200], Step [3/7], Loss: 0.0016, Accuracy: 0.9688\n",
      "Epoch [55/200], Step [4/7], Loss: 0.0013, Accuracy: 0.9375\n",
      "Epoch [55/200], Step [5/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [55/200], Step [6/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [55/200], Step [7/7], Loss: 0.0020, Accuracy: 1.0000\n",
      "Epoch [56/200], Step [1/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [56/200], Step [2/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [56/200], Step [3/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [56/200], Step [4/7], Loss: 0.0007, Accuracy: 0.9688\n",
      "Epoch [56/200], Step [5/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [56/200], Step [6/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [56/200], Step [7/7], Loss: 0.0022, Accuracy: 0.8750\n",
      "Epoch [57/200], Step [1/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [57/200], Step [2/7], Loss: 0.0012, Accuracy: 0.9688\n",
      "Epoch [57/200], Step [3/7], Loss: 0.0016, Accuracy: 0.9062\n",
      "Epoch [57/200], Step [4/7], Loss: 0.0012, Accuracy: 0.9375\n",
      "Epoch [57/200], Step [5/7], Loss: 0.0012, Accuracy: 0.9688\n",
      "Epoch [57/200], Step [6/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [57/200], Step [7/7], Loss: 0.0022, Accuracy: 0.8750\n",
      "Epoch [58/200], Step [1/7], Loss: 0.0011, Accuracy: 0.9688\n",
      "Epoch [58/200], Step [2/7], Loss: 0.0014, Accuracy: 0.9688\n",
      "Epoch [58/200], Step [3/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [58/200], Step [4/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [58/200], Step [5/7], Loss: 0.0009, Accuracy: 0.9688\n",
      "Epoch [58/200], Step [6/7], Loss: 0.0011, Accuracy: 0.9688\n",
      "Epoch [58/200], Step [7/7], Loss: 0.0014, Accuracy: 1.0000\n",
      "Epoch [59/200], Step [1/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [59/200], Step [2/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [59/200], Step [3/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [59/200], Step [4/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [59/200], Step [5/7], Loss: 0.0019, Accuracy: 0.9688\n",
      "Epoch [59/200], Step [6/7], Loss: 0.0009, Accuracy: 0.9688\n",
      "Epoch [59/200], Step [7/7], Loss: 0.0073, Accuracy: 0.8750\n",
      "Epoch [60/200], Step [1/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [60/200], Step [2/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [60/200], Step [3/7], Loss: 0.0018, Accuracy: 0.9375\n",
      "Epoch [60/200], Step [4/7], Loss: 0.0032, Accuracy: 0.9375\n",
      "Epoch [60/200], Step [5/7], Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch [60/200], Step [6/7], Loss: 0.0024, Accuracy: 0.9688\n",
      "Epoch [60/200], Step [7/7], Loss: 0.0052, Accuracy: 0.7500\n",
      "Epoch [61/200], Step [1/7], Loss: 0.0008, Accuracy: 0.9688\n",
      "Epoch [61/200], Step [2/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [61/200], Step [3/7], Loss: 0.0015, Accuracy: 0.9375\n",
      "Epoch [61/200], Step [4/7], Loss: 0.0023, Accuracy: 0.9375\n",
      "Epoch [61/200], Step [5/7], Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch [61/200], Step [6/7], Loss: 0.0015, Accuracy: 0.9375\n",
      "Epoch [61/200], Step [7/7], Loss: 0.0062, Accuracy: 0.7500\n",
      "Epoch [62/200], Step [1/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [62/200], Step [2/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [62/200], Step [3/7], Loss: 0.0011, Accuracy: 1.0000\n",
      "Epoch [62/200], Step [4/7], Loss: 0.0011, Accuracy: 0.9688\n",
      "Epoch [62/200], Step [5/7], Loss: 0.0013, Accuracy: 1.0000\n",
      "Epoch [62/200], Step [6/7], Loss: 0.0022, Accuracy: 0.9375\n",
      "Epoch [62/200], Step [7/7], Loss: 0.0121, Accuracy: 0.6250\n",
      "Epoch [63/200], Step [1/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [63/200], Step [2/7], Loss: 0.0023, Accuracy: 0.9062\n",
      "Epoch [63/200], Step [3/7], Loss: 0.0021, Accuracy: 0.9062\n",
      "Epoch [63/200], Step [4/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [63/200], Step [5/7], Loss: 0.0026, Accuracy: 0.9062\n",
      "Epoch [63/200], Step [6/7], Loss: 0.0023, Accuracy: 0.9375\n",
      "Epoch [63/200], Step [7/7], Loss: 0.0022, Accuracy: 1.0000\n",
      "Epoch [64/200], Step [1/7], Loss: 0.0013, Accuracy: 1.0000\n",
      "Epoch [64/200], Step [2/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [64/200], Step [3/7], Loss: 0.0015, Accuracy: 1.0000\n",
      "Epoch [64/200], Step [4/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [64/200], Step [5/7], Loss: 0.0023, Accuracy: 0.9375\n",
      "Epoch [64/200], Step [6/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [64/200], Step [7/7], Loss: 0.0065, Accuracy: 0.7500\n",
      "Epoch [65/200], Step [1/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [65/200], Step [2/7], Loss: 0.0012, Accuracy: 0.9688\n",
      "Epoch [65/200], Step [3/7], Loss: 0.0013, Accuracy: 1.0000\n",
      "Epoch [65/200], Step [4/7], Loss: 0.0008, Accuracy: 0.9688\n",
      "Epoch [65/200], Step [5/7], Loss: 0.0010, Accuracy: 0.9688\n",
      "Epoch [65/200], Step [6/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [65/200], Step [7/7], Loss: 0.0038, Accuracy: 1.0000\n",
      "Epoch [66/200], Step [1/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [66/200], Step [2/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [66/200], Step [3/7], Loss: 0.0016, Accuracy: 0.9688\n",
      "Epoch [66/200], Step [4/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [66/200], Step [5/7], Loss: 0.0014, Accuracy: 0.9688\n",
      "Epoch [66/200], Step [6/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [66/200], Step [7/7], Loss: 0.0117, Accuracy: 0.7500\n",
      "Epoch [67/200], Step [1/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [67/200], Step [2/7], Loss: 0.0017, Accuracy: 0.9688\n",
      "Epoch [67/200], Step [3/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [67/200], Step [4/7], Loss: 0.0007, Accuracy: 0.9688\n",
      "Epoch [67/200], Step [5/7], Loss: 0.0015, Accuracy: 0.9688\n",
      "Epoch [67/200], Step [6/7], Loss: 0.0020, Accuracy: 0.9688\n",
      "Epoch [67/200], Step [7/7], Loss: 0.0033, Accuracy: 0.8750\n",
      "Epoch [68/200], Step [1/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [68/200], Step [2/7], Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch [68/200], Step [3/7], Loss: 0.0009, Accuracy: 0.9688\n",
      "Epoch [68/200], Step [4/7], Loss: 0.0012, Accuracy: 0.9688\n",
      "Epoch [68/200], Step [5/7], Loss: 0.0010, Accuracy: 0.9375\n",
      "Epoch [68/200], Step [6/7], Loss: 0.0018, Accuracy: 1.0000\n",
      "Epoch [68/200], Step [7/7], Loss: 0.0027, Accuracy: 0.8750\n",
      "Epoch [69/200], Step [1/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [69/200], Step [2/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [69/200], Step [3/7], Loss: 0.0011, Accuracy: 0.9688\n",
      "Epoch [69/200], Step [4/7], Loss: 0.0027, Accuracy: 0.9375\n",
      "Epoch [69/200], Step [5/7], Loss: 0.0012, Accuracy: 0.9688\n",
      "Epoch [69/200], Step [6/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [69/200], Step [7/7], Loss: 0.0030, Accuracy: 0.8750\n",
      "Epoch [70/200], Step [1/7], Loss: 0.0017, Accuracy: 0.9062\n",
      "Epoch [70/200], Step [2/7], Loss: 0.0009, Accuracy: 0.9688\n",
      "Epoch [70/200], Step [3/7], Loss: 0.0009, Accuracy: 0.9688\n",
      "Epoch [70/200], Step [4/7], Loss: 0.0011, Accuracy: 1.0000\n",
      "Epoch [70/200], Step [5/7], Loss: 0.0014, Accuracy: 0.9375\n",
      "Epoch [70/200], Step [6/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [70/200], Step [7/7], Loss: 0.0024, Accuracy: 1.0000\n",
      "Epoch [71/200], Step [1/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [71/200], Step [2/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [71/200], Step [3/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [71/200], Step [4/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [71/200], Step [5/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [71/200], Step [6/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [71/200], Step [7/7], Loss: 0.0040, Accuracy: 0.8750\n",
      "Epoch [72/200], Step [1/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [72/200], Step [2/7], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [72/200], Step [3/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [72/200], Step [4/7], Loss: 0.0012, Accuracy: 0.9688\n",
      "Epoch [72/200], Step [5/7], Loss: 0.0005, Accuracy: 0.9688\n",
      "Epoch [72/200], Step [6/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [72/200], Step [7/7], Loss: 0.0081, Accuracy: 0.7500\n",
      "Epoch [73/200], Step [1/7], Loss: 0.0010, Accuracy: 0.9688\n",
      "Epoch [73/200], Step [2/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [73/200], Step [3/7], Loss: 0.0010, Accuracy: 0.9688\n",
      "Epoch [73/200], Step [4/7], Loss: 0.0017, Accuracy: 0.9688\n",
      "Epoch [73/200], Step [5/7], Loss: 0.0028, Accuracy: 0.9062\n",
      "Epoch [73/200], Step [6/7], Loss: 0.0023, Accuracy: 0.9375\n",
      "Epoch [73/200], Step [7/7], Loss: 0.0054, Accuracy: 0.8750\n",
      "Epoch [74/200], Step [1/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [74/200], Step [2/7], Loss: 0.0013, Accuracy: 0.9688\n",
      "Epoch [74/200], Step [3/7], Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch [74/200], Step [4/7], Loss: 0.0019, Accuracy: 0.9062\n",
      "Epoch [74/200], Step [5/7], Loss: 0.0026, Accuracy: 0.9375\n",
      "Epoch [74/200], Step [6/7], Loss: 0.0033, Accuracy: 0.9062\n",
      "Epoch [74/200], Step [7/7], Loss: 0.0016, Accuracy: 1.0000\n",
      "Epoch [75/200], Step [1/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [75/200], Step [2/7], Loss: 0.0014, Accuracy: 0.9688\n",
      "Epoch [75/200], Step [3/7], Loss: 0.0020, Accuracy: 0.9062\n",
      "Epoch [75/200], Step [4/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [75/200], Step [5/7], Loss: 0.0011, Accuracy: 0.9688\n",
      "Epoch [75/200], Step [6/7], Loss: 0.0025, Accuracy: 0.9375\n",
      "Epoch [75/200], Step [7/7], Loss: 0.0023, Accuracy: 0.8750\n",
      "Epoch [76/200], Step [1/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [76/200], Step [2/7], Loss: 0.0019, Accuracy: 0.9375\n",
      "Epoch [76/200], Step [3/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [76/200], Step [4/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [76/200], Step [5/7], Loss: 0.0024, Accuracy: 0.9062\n",
      "Epoch [76/200], Step [6/7], Loss: 0.0028, Accuracy: 0.9375\n",
      "Epoch [76/200], Step [7/7], Loss: 0.0106, Accuracy: 0.6250\n",
      "Epoch [77/200], Step [1/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [77/200], Step [2/7], Loss: 0.0009, Accuracy: 0.9688\n",
      "Epoch [77/200], Step [3/7], Loss: 0.0019, Accuracy: 0.9375\n",
      "Epoch [77/200], Step [4/7], Loss: 0.0029, Accuracy: 0.9688\n",
      "Epoch [77/200], Step [5/7], Loss: 0.0032, Accuracy: 0.8750\n",
      "Epoch [77/200], Step [6/7], Loss: 0.0017, Accuracy: 0.9375\n",
      "Epoch [77/200], Step [7/7], Loss: 0.0055, Accuracy: 0.7500\n",
      "Epoch [78/200], Step [1/7], Loss: 0.0009, Accuracy: 0.9688\n",
      "Epoch [78/200], Step [2/7], Loss: 0.0023, Accuracy: 0.8750\n",
      "Epoch [78/200], Step [3/7], Loss: 0.0013, Accuracy: 0.9688\n",
      "Epoch [78/200], Step [4/7], Loss: 0.0023, Accuracy: 0.9375\n",
      "Epoch [78/200], Step [5/7], Loss: 0.0045, Accuracy: 0.9375\n",
      "Epoch [78/200], Step [6/7], Loss: 0.0017, Accuracy: 0.9688\n",
      "Epoch [78/200], Step [7/7], Loss: 0.0016, Accuracy: 1.0000\n",
      "Epoch [79/200], Step [1/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [79/200], Step [2/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [79/200], Step [3/7], Loss: 0.0026, Accuracy: 0.9062\n",
      "Epoch [79/200], Step [4/7], Loss: 0.0015, Accuracy: 0.9688\n",
      "Epoch [79/200], Step [5/7], Loss: 0.0022, Accuracy: 0.8750\n",
      "Epoch [79/200], Step [6/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [79/200], Step [7/7], Loss: 0.0036, Accuracy: 0.8750\n",
      "Epoch [80/200], Step [1/7], Loss: 0.0011, Accuracy: 1.0000\n",
      "Epoch [80/200], Step [2/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [80/200], Step [3/7], Loss: 0.0018, Accuracy: 0.9688\n",
      "Epoch [80/200], Step [4/7], Loss: 0.0017, Accuracy: 0.9375\n",
      "Epoch [80/200], Step [5/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [80/200], Step [6/7], Loss: 0.0020, Accuracy: 0.9688\n",
      "Epoch [80/200], Step [7/7], Loss: 0.0043, Accuracy: 0.8750\n",
      "Epoch [81/200], Step [1/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [81/200], Step [2/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [81/200], Step [3/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [81/200], Step [4/7], Loss: 0.0010, Accuracy: 0.9688\n",
      "Epoch [81/200], Step [5/7], Loss: 0.0008, Accuracy: 0.9688\n",
      "Epoch [81/200], Step [6/7], Loss: 0.0013, Accuracy: 0.9688\n",
      "Epoch [81/200], Step [7/7], Loss: 0.0017, Accuracy: 1.0000\n",
      "Epoch [82/200], Step [1/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [82/200], Step [2/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [82/200], Step [3/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [82/200], Step [4/7], Loss: 0.0014, Accuracy: 0.9375\n",
      "Epoch [82/200], Step [5/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [82/200], Step [6/7], Loss: 0.0010, Accuracy: 0.9688\n",
      "Epoch [82/200], Step [7/7], Loss: 0.0048, Accuracy: 0.7500\n",
      "Epoch [83/200], Step [1/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [83/200], Step [2/7], Loss: 0.0017, Accuracy: 0.9688\n",
      "Epoch [83/200], Step [3/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [83/200], Step [4/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [83/200], Step [5/7], Loss: 0.0019, Accuracy: 0.9375\n",
      "Epoch [83/200], Step [6/7], Loss: 0.0014, Accuracy: 0.9688\n",
      "Epoch [83/200], Step [7/7], Loss: 0.0025, Accuracy: 0.8750\n",
      "Epoch [84/200], Step [1/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [84/200], Step [2/7], Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch [84/200], Step [3/7], Loss: 0.0016, Accuracy: 0.9688\n",
      "Epoch [84/200], Step [4/7], Loss: 0.0006, Accuracy: 0.9688\n",
      "Epoch [84/200], Step [5/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [84/200], Step [6/7], Loss: 0.0011, Accuracy: 0.9688\n",
      "Epoch [84/200], Step [7/7], Loss: 0.0051, Accuracy: 0.5000\n",
      "Epoch [85/200], Step [1/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [85/200], Step [2/7], Loss: 0.0010, Accuracy: 0.9688\n",
      "Epoch [85/200], Step [3/7], Loss: 0.0040, Accuracy: 0.9062\n",
      "Epoch [85/200], Step [4/7], Loss: 0.0015, Accuracy: 0.9688\n",
      "Epoch [85/200], Step [5/7], Loss: 0.0018, Accuracy: 0.9688\n",
      "Epoch [85/200], Step [6/7], Loss: 0.0022, Accuracy: 0.9062\n",
      "Epoch [85/200], Step [7/7], Loss: 0.0066, Accuracy: 0.8750\n",
      "Epoch [86/200], Step [1/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [86/200], Step [2/7], Loss: 0.0008, Accuracy: 0.9688\n",
      "Epoch [86/200], Step [3/7], Loss: 0.0010, Accuracy: 0.9688\n",
      "Epoch [86/200], Step [4/7], Loss: 0.0016, Accuracy: 0.9688\n",
      "Epoch [86/200], Step [5/7], Loss: 0.0010, Accuracy: 0.9688\n",
      "Epoch [86/200], Step [6/7], Loss: 0.0021, Accuracy: 0.9375\n",
      "Epoch [86/200], Step [7/7], Loss: 0.0041, Accuracy: 0.8750\n",
      "Epoch [87/200], Step [1/7], Loss: 0.0012, Accuracy: 0.9688\n",
      "Epoch [87/200], Step [2/7], Loss: 0.0027, Accuracy: 0.9375\n",
      "Epoch [87/200], Step [3/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [87/200], Step [4/7], Loss: 0.0041, Accuracy: 0.9062\n",
      "Epoch [87/200], Step [5/7], Loss: 0.0020, Accuracy: 0.9375\n",
      "Epoch [87/200], Step [6/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [87/200], Step [7/7], Loss: 0.0017, Accuracy: 1.0000\n",
      "Epoch [88/200], Step [1/7], Loss: 0.0011, Accuracy: 1.0000\n",
      "Epoch [88/200], Step [2/7], Loss: 0.0009, Accuracy: 0.9688\n",
      "Epoch [88/200], Step [3/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [88/200], Step [4/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [88/200], Step [5/7], Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch [88/200], Step [6/7], Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch [88/200], Step [7/7], Loss: 0.0030, Accuracy: 0.8750\n",
      "Epoch [89/200], Step [1/7], Loss: 0.0009, Accuracy: 0.9688\n",
      "Epoch [89/200], Step [2/7], Loss: 0.0010, Accuracy: 0.9688\n",
      "Epoch [89/200], Step [3/7], Loss: 0.0016, Accuracy: 0.9375\n",
      "Epoch [89/200], Step [4/7], Loss: 0.0009, Accuracy: 0.9688\n",
      "Epoch [89/200], Step [5/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [89/200], Step [6/7], Loss: 0.0013, Accuracy: 0.9688\n",
      "Epoch [89/200], Step [7/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [90/200], Step [1/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [90/200], Step [2/7], Loss: 0.0008, Accuracy: 0.9688\n",
      "Epoch [90/200], Step [3/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [90/200], Step [4/7], Loss: 0.0006, Accuracy: 0.9688\n",
      "Epoch [90/200], Step [5/7], Loss: 0.0012, Accuracy: 0.9688\n",
      "Epoch [90/200], Step [6/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [90/200], Step [7/7], Loss: 0.0012, Accuracy: 1.0000\n",
      "Epoch [91/200], Step [1/7], Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch [91/200], Step [2/7], Loss: 0.0007, Accuracy: 0.9688\n",
      "Epoch [91/200], Step [3/7], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [91/200], Step [4/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [91/200], Step [5/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [91/200], Step [6/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [91/200], Step [7/7], Loss: 0.0063, Accuracy: 0.7500\n",
      "Epoch [92/200], Step [1/7], Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch [92/200], Step [2/7], Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch [92/200], Step [3/7], Loss: 0.0007, Accuracy: 0.9688\n",
      "Epoch [92/200], Step [4/7], Loss: 0.0004, Accuracy: 0.9688\n",
      "Epoch [92/200], Step [5/7], Loss: 0.0025, Accuracy: 0.9688\n",
      "Epoch [92/200], Step [6/7], Loss: 0.0016, Accuracy: 0.9375\n",
      "Epoch [92/200], Step [7/7], Loss: 0.0042, Accuracy: 0.8750\n",
      "Epoch [93/200], Step [1/7], Loss: 0.0012, Accuracy: 1.0000\n",
      "Epoch [93/200], Step [2/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [93/200], Step [3/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [93/200], Step [4/7], Loss: 0.0021, Accuracy: 0.9375\n",
      "Epoch [93/200], Step [5/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [93/200], Step [6/7], Loss: 0.0009, Accuracy: 0.9688\n",
      "Epoch [93/200], Step [7/7], Loss: 0.0063, Accuracy: 0.7500\n",
      "Epoch [94/200], Step [1/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [94/200], Step [2/7], Loss: 0.0012, Accuracy: 0.9688\n",
      "Epoch [94/200], Step [3/7], Loss: 0.0036, Accuracy: 0.8438\n",
      "Epoch [94/200], Step [4/7], Loss: 0.0019, Accuracy: 0.9062\n",
      "Epoch [94/200], Step [5/7], Loss: 0.0043, Accuracy: 0.9375\n",
      "Epoch [94/200], Step [6/7], Loss: 0.0010, Accuracy: 0.9688\n",
      "Epoch [94/200], Step [7/7], Loss: 0.0044, Accuracy: 0.8750\n",
      "Epoch [95/200], Step [1/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [95/200], Step [2/7], Loss: 0.0009, Accuracy: 0.9688\n",
      "Epoch [95/200], Step [3/7], Loss: 0.0015, Accuracy: 0.9688\n",
      "Epoch [95/200], Step [4/7], Loss: 0.0021, Accuracy: 0.9688\n",
      "Epoch [95/200], Step [5/7], Loss: 0.0030, Accuracy: 0.9375\n",
      "Epoch [95/200], Step [6/7], Loss: 0.0019, Accuracy: 0.9375\n",
      "Epoch [95/200], Step [7/7], Loss: 0.0106, Accuracy: 0.6250\n",
      "Epoch [96/200], Step [1/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [96/200], Step [2/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [96/200], Step [3/7], Loss: 0.0054, Accuracy: 0.9375\n",
      "Epoch [96/200], Step [4/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [96/200], Step [5/7], Loss: 0.0044, Accuracy: 0.8750\n",
      "Epoch [96/200], Step [6/7], Loss: 0.0015, Accuracy: 0.9688\n",
      "Epoch [96/200], Step [7/7], Loss: 0.0159, Accuracy: 0.6250\n",
      "Epoch [97/200], Step [1/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [97/200], Step [2/7], Loss: 0.0041, Accuracy: 0.9062\n",
      "Epoch [97/200], Step [3/7], Loss: 0.0014, Accuracy: 0.9688\n",
      "Epoch [97/200], Step [4/7], Loss: 0.0015, Accuracy: 0.9688\n",
      "Epoch [97/200], Step [5/7], Loss: 0.0027, Accuracy: 0.9062\n",
      "Epoch [97/200], Step [6/7], Loss: 0.0025, Accuracy: 0.9375\n",
      "Epoch [97/200], Step [7/7], Loss: 0.0040, Accuracy: 0.7500\n",
      "Epoch [98/200], Step [1/7], Loss: 0.0014, Accuracy: 0.9688\n",
      "Epoch [98/200], Step [2/7], Loss: 0.0020, Accuracy: 0.9688\n",
      "Epoch [98/200], Step [3/7], Loss: 0.0011, Accuracy: 1.0000\n",
      "Epoch [98/200], Step [4/7], Loss: 0.0034, Accuracy: 0.8750\n",
      "Epoch [98/200], Step [5/7], Loss: 0.0014, Accuracy: 0.9688\n",
      "Epoch [98/200], Step [6/7], Loss: 0.0023, Accuracy: 0.9688\n",
      "Epoch [98/200], Step [7/7], Loss: 0.0072, Accuracy: 0.7500\n",
      "Epoch [99/200], Step [1/7], Loss: 0.0029, Accuracy: 0.8438\n",
      "Epoch [99/200], Step [2/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [99/200], Step [3/7], Loss: 0.0020, Accuracy: 0.9375\n",
      "Epoch [99/200], Step [4/7], Loss: 0.0012, Accuracy: 0.9688\n",
      "Epoch [99/200], Step [5/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [99/200], Step [6/7], Loss: 0.0027, Accuracy: 0.9375\n",
      "Epoch [99/200], Step [7/7], Loss: 0.0066, Accuracy: 0.8750\n",
      "Epoch [100/200], Step [1/7], Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch [100/200], Step [2/7], Loss: 0.0013, Accuracy: 0.9688\n",
      "Epoch [100/200], Step [3/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [100/200], Step [4/7], Loss: 0.0012, Accuracy: 1.0000\n",
      "Epoch [100/200], Step [5/7], Loss: 0.0022, Accuracy: 0.9688\n",
      "Epoch [100/200], Step [6/7], Loss: 0.0011, Accuracy: 1.0000\n",
      "Epoch [100/200], Step [7/7], Loss: 0.0067, Accuracy: 0.8750\n",
      "Epoch [101/200], Step [1/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [101/200], Step [2/7], Loss: 0.0009, Accuracy: 0.9688\n",
      "Epoch [101/200], Step [3/7], Loss: 0.0017, Accuracy: 0.9688\n",
      "Epoch [101/200], Step [4/7], Loss: 0.0013, Accuracy: 0.9688\n",
      "Epoch [101/200], Step [5/7], Loss: 0.0022, Accuracy: 0.8750\n",
      "Epoch [101/200], Step [6/7], Loss: 0.0022, Accuracy: 0.9375\n",
      "Epoch [101/200], Step [7/7], Loss: 0.0022, Accuracy: 1.0000\n",
      "Epoch [102/200], Step [1/7], Loss: 0.0019, Accuracy: 0.9375\n",
      "Epoch [102/200], Step [2/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [102/200], Step [3/7], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [102/200], Step [4/7], Loss: 0.0041, Accuracy: 0.8750\n",
      "Epoch [102/200], Step [5/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [102/200], Step [6/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [102/200], Step [7/7], Loss: 0.0074, Accuracy: 0.7500\n",
      "Epoch [103/200], Step [1/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [103/200], Step [2/7], Loss: 0.0015, Accuracy: 0.9688\n",
      "Epoch [103/200], Step [3/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [103/200], Step [4/7], Loss: 0.0017, Accuracy: 0.9375\n",
      "Epoch [103/200], Step [5/7], Loss: 0.0016, Accuracy: 0.9375\n",
      "Epoch [103/200], Step [6/7], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [103/200], Step [7/7], Loss: 0.0056, Accuracy: 0.7500\n",
      "Epoch [104/200], Step [1/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [104/200], Step [2/7], Loss: 0.0010, Accuracy: 0.9688\n",
      "Epoch [104/200], Step [3/7], Loss: 0.0007, Accuracy: 0.9688\n",
      "Epoch [104/200], Step [4/7], Loss: 0.0021, Accuracy: 0.9062\n",
      "Epoch [104/200], Step [5/7], Loss: 0.0046, Accuracy: 0.8750\n",
      "Epoch [104/200], Step [6/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [104/200], Step [7/7], Loss: 0.0068, Accuracy: 0.7500\n",
      "Epoch [105/200], Step [1/7], Loss: 0.0015, Accuracy: 0.9375\n",
      "Epoch [105/200], Step [2/7], Loss: 0.0023, Accuracy: 0.9062\n",
      "Epoch [105/200], Step [3/7], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [105/200], Step [4/7], Loss: 0.0012, Accuracy: 0.9688\n",
      "Epoch [105/200], Step [5/7], Loss: 0.0012, Accuracy: 0.9688\n",
      "Epoch [105/200], Step [6/7], Loss: 0.0009, Accuracy: 0.9688\n",
      "Epoch [105/200], Step [7/7], Loss: 0.0069, Accuracy: 0.7500\n",
      "Epoch [106/200], Step [1/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [106/200], Step [2/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [106/200], Step [3/7], Loss: 0.0013, Accuracy: 0.9688\n",
      "Epoch [106/200], Step [4/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [106/200], Step [5/7], Loss: 0.0009, Accuracy: 1.0000\n",
      "Epoch [106/200], Step [6/7], Loss: 0.0014, Accuracy: 1.0000\n",
      "Epoch [106/200], Step [7/7], Loss: 0.0023, Accuracy: 0.8750\n",
      "Epoch [107/200], Step [1/7], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [107/200], Step [2/7], Loss: 0.0008, Accuracy: 0.9688\n",
      "Epoch [107/200], Step [3/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [107/200], Step [4/7], Loss: 0.0014, Accuracy: 0.9688\n",
      "Epoch [107/200], Step [5/7], Loss: 0.0006, Accuracy: 1.0000\n",
      "Epoch [107/200], Step [6/7], Loss: 0.0014, Accuracy: 0.9688\n",
      "Epoch [107/200], Step [7/7], Loss: 0.0147, Accuracy: 0.3750\n",
      "Epoch [108/200], Step [1/7], Loss: 0.0005, Accuracy: 0.9688\n",
      "Epoch [108/200], Step [2/7], Loss: 0.0019, Accuracy: 0.9375\n",
      "Epoch [108/200], Step [3/7], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [108/200], Step [4/7], Loss: 0.0038, Accuracy: 0.8750\n",
      "Epoch [108/200], Step [5/7], Loss: 0.0011, Accuracy: 0.9688\n",
      "Epoch [108/200], Step [6/7], Loss: 0.0029, Accuracy: 0.9062\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(data_loader):\n",
    "        # Move inputs and labels to the same device as the model\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        # print(labels.view(-1, 1))\n",
    "        # print(outputs.shape)\n",
    "        # print(labels.shape)\n",
    "        loss = criterion(outputs, labels.view(-1).long())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # Accumulate total loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # if (i+1) % 100 == 0:\n",
    "        avg_loss = total_loss / 100\n",
    "        accuracy = correct_predictions / total_samples\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(data_loader)}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "print('Training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
