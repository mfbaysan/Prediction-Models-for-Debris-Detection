GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\trainer\configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name     | Type               | Params
------------------------------------------------
0 | lstm     | LSTM               | 316 K
1 | fc       | Linear             | 195
2 | accuracy | MulticlassAccuracy | 0
------------------------------------------------
316 K     Trainable params
0         Non-trainable params
316 K     Total params
1.267     Total estimated model params size (MB)
C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\loops\fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Traceback (most recent call last):
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pandas\core\indexes\base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
  File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\\_libs\\hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas\\_libs\\hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 2
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "C:\Users\fatih\PycharmProjects\model_implementation\main.py", line 100, in <module>
    trainer.fit(model, data_module)
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\trainer\trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\trainer\call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\trainer\trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\trainer\trainer.py", line 987, in _run
    results = self._run_stage()
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\trainer\trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\loops\fit_loop.py", line 205, in run
    self.advance()
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\loops\fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\loops\training_epoch_loop.py", line 140, in run
    self.advance(data_fetcher)
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\loops\training_epoch_loop.py", line 212, in advance
    batch, _, __ = next(data_fetcher)
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\loops\fetchers.py", line 133, in __next__
    batch = super().__next__()
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\loops\fetchers.py", line 60, in __next__
    batch = next(self.iterator)
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\utilities\combined_loader.py", line 341, in __next__
    out = next(self._iterator)
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pytorch_lightning\utilities\combined_loader.py", line 78, in __next__
    out[i] = next(self.iterators[i])
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\torch\utils\data\dataloader.py", line 631, in __next__
    data = self._next_data()
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\torch\utils\data\dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pandas\core\frame.py", line 4090, in __getitem__
    indexer = self.columns.get_loc(key)
  File "C:\Users\fatih\PycharmProjects\model_implementation\venv\lib\site-packages\pandas\core\indexes\base.py", line 3812, in get_loc
    raise KeyError(key) from err
KeyError: 2
Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]