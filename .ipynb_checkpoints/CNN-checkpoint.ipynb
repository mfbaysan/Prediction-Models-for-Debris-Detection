{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_pickle_files(folder_path):\n",
    "    \"\"\"\n",
    "    Get all the .pickle files from a folder.\n",
    "\n",
    "    Args:\n",
    "    - folder_path (str): Path to the folder containing .pickle files\n",
    "\n",
    "    Returns:\n",
    "    - List of .pickle files\n",
    "    \"\"\"\n",
    "    pickle_files = [file for file in os.listdir(folder_path) if file.endswith('.pickle')]\n",
    "    return pickle_files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def convert_to_3d_tensors(radar_return):\n",
    "    \"\"\"\n",
    "    Convert radar_return values to 3D torch tensors.\n",
    "\n",
    "    Args:\n",
    "    - radar_return (ndarray): 2D matrix consisting of complex numbers\n",
    "\n",
    "    Returns:\n",
    "    - 3D torch tensor with shape (width, height, channels)\n",
    "    \"\"\"\n",
    "    real_part = radar_return.real\n",
    "    imag_part = radar_return.imag\n",
    "    # Stack real and imaginary parts to create a 3D tensor with two channels\n",
    "    tensor = torch.stack((real_part, imag_part), axis=-1)\n",
    "    return tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def process_pickle_files(folder_path):\n",
    "    \"\"\"\n",
    "    Process all .pickle files in a folder.\n",
    "\n",
    "    Args:\n",
    "    - folder_path (str): Path to the folder containing .pickle files\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing all the samples\n",
    "    \"\"\"\n",
    "    # Get .pickle files\n",
    "    pickle_files = get_pickle_files(folder_path)\n",
    "    data = []\n",
    "    for file_name in pickle_files:\n",
    "        with open(os.path.join(folder_path, file_name), 'rb') as f:\n",
    "            file_data = pickle.load(f)\n",
    "            for obj_id, radar_return in file_data.items():\n",
    "                # Convert radar_return to 3D torch tensor\n",
    "                tensor = convert_to_3d_tensors(radar_return)\n",
    "                # Append object id and tensor to data list\n",
    "                data.append({'object_id': obj_id, 'tensor': tensor})\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'real'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Example usage\u001B[39;00m\n\u001B[0;32m      2\u001B[0m folder_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOverfit_data\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 3\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_pickle_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfolder_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[9], line 19\u001B[0m, in \u001B[0;36mprocess_pickle_files\u001B[1;34m(folder_path)\u001B[0m\n\u001B[0;32m     16\u001B[0m file_data \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(f)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m obj_id, radar_return \u001B[38;5;129;01min\u001B[39;00m file_data\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;66;03m# Convert radar_return to 3D torch tensor\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m     tensor \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_to_3d_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mradar_return\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;66;03m# Append object id and tensor to data list\u001B[39;00m\n\u001B[0;32m     21\u001B[0m     data\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobject_id\u001B[39m\u001B[38;5;124m'\u001B[39m: obj_id, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensor\u001B[39m\u001B[38;5;124m'\u001B[39m: tensor})\n",
      "Cell \u001B[1;32mIn[8], line 11\u001B[0m, in \u001B[0;36mconvert_to_3d_tensors\u001B[1;34m(radar_return)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert_to_3d_tensors\u001B[39m(radar_return):\n\u001B[0;32m      2\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m    Convert radar_return values to 3D torch tensors.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;124;03m    - 3D torch tensor with shape (width, height, channels)\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m     real_part \u001B[38;5;241m=\u001B[39m \u001B[43mradar_return\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreal\u001B[49m\n\u001B[0;32m     12\u001B[0m     imag_part \u001B[38;5;241m=\u001B[39m radar_return\u001B[38;5;241m.\u001B[39mimag\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;66;03m# Stack real and imaginary parts to create a 3D tensor with two channels\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'str' object has no attribute 'real'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "folder_path = 'Overfit_data'\n",
    "df = process_pickle_files(folder_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
